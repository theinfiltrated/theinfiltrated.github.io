<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
<title type="text">Francesco Provino</title>
<generator uri="https://github.com/jekyll/jekyll">Jekyll</generator>
<link rel="self" type="application/atom+xml" href="http://francescoprovino.com/feed.xml" />
<link rel="alternate" type="text/html" href="http://francescoprovino.com" />
<updated>2015-10-30T18:01:30+01:00</updated>
<id>http://francescoprovino.com/</id>
<author>
  <name>Francesco Provino</name>
  <uri>http://francescoprovino.com/</uri>
  <email>me@francescoprovino.com</email>
</author>


  

<entry>
  <title type="html"><![CDATA[Perché usare distro enterprise?]]></title>
  <link rel="alternate" type="text/html" href="http://francescoprovino.com/distro_enterprise/" />
  <id>http://francescoprovino.com/distro_enterprise</id>
  <published>2015-08-24T00:00:00+02:00</published>
  <updated>2015-08-24T00:00:00+02:00</updated>
  <author>
    <name>Francesco Provino</name>
    <uri>http://francescoprovino.com</uri>
    <email>me@francescoprovino.com</email>
  </author>
  <content type="html">
    &lt;p&gt;Uno dei consigli più gettonati nei vari forum &lt;strong&gt;per principianti&lt;/strong&gt; riguardati Linux è: &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Non ti funziona $nuova_versione_ambiente_grafico? &lt;br /&gt; Prova $distribuzione_misconosciuta!&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;La multipolarità della comunità OSS ha permesso la nascita e l’evoluzione di progetti importanti, e la loro gestione “poco business-oriented” ha consentito che si sviluppassero in direzioni spesso più interessanti e funzionali rispetto ad equivalenti commerciali.
Dando uno sguardo alla situazione attuale dell’ecosistema Linux però, non si può ignorare come sia il kernel, sia l’ambiente GNU, siano essenzialmente mantenuti da una moltitudine di aziende; gli ultimi &lt;a href=&quot;http://www.linuxfoundation.org/news-media/announcements/2015/02/linux-foundation-releases-linux-development-report&quot;&gt;rapporti a riguardo&lt;/a&gt; parlano di come oltre l’80% degli sviluppatori siano pagati per il loro contributo dalle oltre 1200 aziende attivamente coinvolte: fra i top contributors spiccano Intel, Red Hat, Samsung, IBM, SUSE e Google.&lt;/p&gt;

&lt;p&gt;È possibile trovare la concretizzazione di questi contributi professionali e di qualità in una terna (anche se ho delle riserve sul nuovo player) di distribuzioni che chiameremo &lt;strong&gt;distro enterprise&lt;/strong&gt;, ovvero distribuzioni di Linux destinate ad ambienti di produzione per le quali viene offerto supporto commerciale e lo sviluppo/QA viene curato internamente; ci stiamo riferendo naturalmente a Red Hat Enterprise Linux (RHEL per gli amici), SUSE Enterprise Linux e Ubuntu Server.&lt;/p&gt;

&lt;p&gt;In questo post volevo esplorare alcuni loro punti di forza che secondo me le rendono una scelta irrinunciabile quando si deve &lt;em&gt;lavorare&lt;/em&gt;, in senso esteso, con il computer. &lt;br /&gt;
Perché le macchine nascono per fare lavoro al posto dell’uomo, right?&lt;/p&gt;

&lt;h2 id=&quot;supporto&quot;&gt;Supporto&lt;/h2&gt;
&lt;p&gt;La possibilità di poter chiamare qualcuno che risolve qualsiasi problema entro le SLA di contratto e che all’occorrenza rilascia anche patch customizzate è &lt;strong&gt;im-pa-ga-bi-le&lt;/strong&gt;. Fesserie bloccanti che a volte tengono fermi progetti per settimane, di solito vengono risolte in poche ore. &lt;/p&gt;

&lt;p&gt;Poiché chi fornisce la distribuzione da assistenza e mantiene/sviluppa &lt;em&gt;tutti&lt;/em&gt; i pacchetti presenti nella distro, si riceve supporto anche su Apache, mySQL ecc; a differenza del mondo Windows dove viene garantito solamente il sistema operativo, e si gioca molto allo scaricabarile per qualsiasi software di terze parti. In genere, è possibile mettere su un sistema di produzione con discrete garanzie di fattibilità e tempistiche.&lt;/p&gt;

&lt;p&gt;Supporto vuol dire anche manutenzione assicurata a lungo termine: la maggior parte delle distribuzioni succitate offre &lt;strong&gt;dieci anni&lt;/strong&gt; di supporto che comprende patch di sicurezza (e non), chiamate di assistenza, nuovo software… insomma, una piattaforma stabile dove poter sviluppare il proprio workflow senza la paura che ci cambi sotto i piedi.&lt;/p&gt;

&lt;h2 id=&quot;compatibilit-hardware-e-software&quot;&gt;Compatibilità Hardware e Software&lt;/h2&gt;
&lt;p&gt;Software di modellazione 3D, schede video high-end, praticamente tutto l’hardware enterprise come HBA, controller RAID e interi servers/soluzioni/infrastrutture… devo aggiungere altro? &lt;br /&gt;
Sì: RHEL è una delle poche distro ad implementare correttamente e di default gli attributi estesi per il filesystem (ovvero, le ACL di Windows) e SUSE vanta una compatibilità spettacolare con Active Directory.&lt;/p&gt;

&lt;h2 id=&quot;possibilit-certificazioni--prospettive-lavorative&quot;&gt;Possibilità certificazioni / Prospettive lavorative&lt;/h2&gt;
&lt;p&gt;Un conto è “&lt;em&gt;so installare Linux, beh, sì&lt;/em&gt;”, un altro è poter affermare “&lt;em&gt;sono certificato come system architect per quell’architettura e blablabla&lt;/em&gt;”; può fare la differenza. &lt;br /&gt; È costoso, è una mezza mafia, ma può fare la differenza. &lt;br /&gt;
Sicuramente conoscere una distribuzione affermata nel panorama enterprise da un marcia in più a parità di curriculum: in generale CentOS è praticamente obbligatoria, ultimamente anche una conoscenza Debian-ish non guasta.&lt;/p&gt;

&lt;h2 id=&quot;stabilit&quot;&gt;Stabilità&lt;/h2&gt;
&lt;p&gt;Inutile negarlo, i bugs bastardi esistono anche su Linux, e spesso le soluzioni non sono né triviali né facilmente attuabili &lt;em&gt;at all&lt;/em&gt;. &lt;br /&gt; Un ciclo di sviluppo più lento e orientato alla produzione, nonché QA sul codice documentato e funzionalità davvero &lt;strong&gt;funzionanti&lt;/strong&gt; sono il miglior biglietto da visita.&lt;/p&gt;

&lt;p&gt;Un esempio? Provate a configurare SELINUX o i pacchetti per l’HA su una distro &lt;em&gt;rolling release&lt;/em&gt;. &lt;br /&gt; E poi ditemi. &lt;br /&gt;
Ogni pacchetto è generalmente testato-integrato per funzionare bene con tutti gli altri, la distribuzione è un &lt;em&gt;unicum&lt;/em&gt; più che essere un’accozzaglia di pacchetti in un calderone, con alcuni presenti solo perché “fa community”, “dobbiamo averli tutti”. &lt;br /&gt; Di contro, il parco software è in genere limitato rispetto ad altre distro; il prezzo del rigore.&lt;/p&gt;

&lt;h2 id=&quot;interoperabilit-fra-versione-commerciale-e-non&quot;&gt;Interoperabilità fra versione commerciale e non&lt;/h2&gt;
&lt;p&gt;La user base delle versioni gratuite (e non solo FLOSS!) di Linux è immensamente più grande di quella delle versioni a pagamento/supportate.&lt;/p&gt;

&lt;p&gt;Una dei grandi vantaggi di RHEL e Ubuntu però, è la possibilità di passare in modo assolutamente indolore dalla versione &lt;em&gt;commerciale&lt;/em&gt; e supportata a quella &lt;em&gt;community&lt;/em&gt;. Ubuntu vende solo il supporto, ergo il problema non esiste. In CentOS/RHEL basta cambiare i repo, le due hanno compatibilità binaria (cambiano loghi e RHN). SUSE/openSUSE pecca un po’ a riguardo, non esiste difatti un equivalente 1:1 di SUSE enterprise. &lt;/p&gt;

&lt;p&gt;È possibile scaricare la versione binaria (oltre ai sorgenti, chiaramente) di SUSE e utilizzarla con i corrispondenti repo community, ma la procedura non è esattamente lineare né “caldeggiata”; tutto il contrario di Ubuntu e CentOS, che hanno guadagnato una gran fetta del loro market share proprio grazie all’ecosistema cantinaro e comunitario che si è creato attorno a loro. 
&lt;br /&gt; SUSE, quando ci svegliamo? &lt;br /&gt;
La spinta all’integrazione con prodotti Microsoft ha curiosi riflessi sulle strategie aziendali…&lt;/p&gt;

&lt;h2 id=&quot;documentazione&quot;&gt;Documentazione&lt;/h2&gt;
&lt;p&gt;Questo è probabilmente il punto più importante della rassegna, il maggiore &lt;em&gt;selling point&lt;/em&gt;; la documentazione di queste distribuzioni, in generale è &lt;strong&gt;OTTIMA&lt;/strong&gt;. 
&lt;br /&gt; Non parlo di “link al forum, link al tutorial, come ha fatto l’utente XY, prova Z”: &lt;strong&gt;ogni&lt;/strong&gt; funzionalità è completamente documentata e la documentazione è fornita insieme alla distro.&lt;/p&gt;

&lt;p&gt;Non mi riferisco al sempreverde &lt;em&gt;man&lt;/em&gt;, ma ad interi portali dedicati solamente a spiegare, fornire esempi, aiutare a costruire configurazioni funzionanti. 
&lt;br /&gt; Aggiornati, corretti, utilizzabili in ogni momento come &lt;em&gt;reference&lt;/em&gt; quando ci si trova in difficoltà. Devo dire che sono anche utili per scoprire funzionalità e pacchetti dei quali non si sospettava l’esistenza, semplicemente confrontando “come lo fa SUSE” &lt;em&gt;vs&lt;/em&gt; “come lo fa RHEL”.&lt;/p&gt;

&lt;h2 id=&quot;un-consiglio&quot;&gt;Un consiglio?&lt;/h2&gt;
&lt;p&gt;Per lavorare, fintantoché potete e non sorgono delle difficoltà insormontabili, usate CentOS. La maggior parte delle soluzioni enterprise sono sviluppate sopra di essa, dai firmware delle SAN; è bene farsi le ossa sugli ambienti realmente utilizzati in produzione.
Se si resta sui repo standard, fatta salvo ovviamente una configurazione corretta, è incredibilmente stabile: la uso correntemente sia come hypervisor (KVM) che come host.&lt;/p&gt;

&lt;p&gt;OpenSUSE/SUSE ha molto senso come ambiente desktop: ottima con KDE4, grande integrazione di default con eventuali sistemi Microsoft o altre terze parti. Inoltre, ultimamente sta prendendo molto piede come piattaforma di storage grazie al supporto per CEPH. La suite di High Availability e supercalcolo dicono funzioni molto bene, ma generalmente sono campi dove si customizza parecchio.&lt;/p&gt;

&lt;p&gt;Ubuntu… sta guadagnando molta popolarità in installazione di OpenStack. Per il resto, la documentazione è poco affidabile/aggiornata/completa rispetto agli altri contenders, e la selezione del software spesso è fatta in modo scellerato, solamente per includere features consumer a scapito della stabilità; come si può includere un kernel &lt;strong&gt;NON&lt;/strong&gt; &lt;em&gt;lts&lt;/em&gt; in una release &lt;em&gt;lts&lt;/em&gt;?! Di contro, è molto aggiornata e alcuni progetti proposti da Canonical sono interessanti (penso a LXD), ma la consiglierei solamente se è impossibile raggiungere il vostro scopo utilizzando le altre due alternative.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;http://francescoprovino.com/distro_enterprise/&quot;&gt;Perché usare distro enterprise?&lt;/a&gt; è stato originariamente pubblicato da Francesco Provino il &lt;a href=&quot;http://francescoprovino.com&quot;&gt;Francesco Provino&lt;/a&gt; su August 24, 2015.&lt;/p&gt;

  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[La grande O nel cielo]]></title>
  <link rel="alternate" type="text/html" href="http://francescoprovino.com/Olivetti/" />
  <id>http://francescoprovino.com/Olivetti</id>
  <published>2015-06-09T00:00:00+02:00</published>
  <updated>2015-06-09T00:00:00+02:00</updated>
  <author>
    <name>Francesco Provino</name>
    <uri>http://francescoprovino.com</uri>
    <email>me@francescoprovino.com</email>
  </author>
  <content type="html">
    &lt;p&gt;Francamente? Io un’idea &lt;a href=&quot;http://www.ilfattoquotidiano.it/2015/06/08/olivetti-30-milioni-di-perdite-lanno-da-10-anni-poche-idee-e-tanti-esuberi/1748088/&quot;&gt;a riguardo&lt;/a&gt; cel’avrei.&lt;/p&gt;

&lt;p&gt;Con quello che è rimasto dell’azienda, assumete una trentina di programmatori/sistemisti/hardwaristi Linux; si trovano abbastanza facilmente, basta fare screening fra i certificati Red Hat.
Fategli sviluppare un sistema centralizzato “&lt;em&gt;All inclusive&lt;/em&gt;” per le PMI, dalla ricezione mail alla bolla da appiccicare sul pacco, che giri tutto su &lt;strong&gt;un&lt;/strong&gt; server (o due, DRBD + clustering applicativo), basato su Linux/KVM; lo stack è già tutto esistente, dall’hypervisor alle applicaizioni client, basta &lt;em&gt;integrarlo&lt;/em&gt; e farne un prodotto &lt;strong&gt;fico&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Sfruttate quel cazzo di nome, fate le porte dell’armadio con un grande &lt;strong&gt;O&lt;/strong&gt; verde a triangolini, scrivetegli sotto &lt;em&gt;POWERED BY LINUX&lt;/em&gt; e pubblicizzatelo con delle rassicuranti schermate che non dicano “Cloud, 2.0, IoT”, ma che facciano vedere un sistema con le finestre e i menù come dio comanda, ché la gente si è rotta delle ultime schizofrenie tablet-style Microsoft (infatti compra Apple) e nella “flessibilità degli applicativi pensati anche per il mobile” ed altra fuffa mediatica crede sempre meno.&lt;/p&gt;

&lt;h3 id=&quot;cosa-mettiamo-stasera-nel-minestrone&quot;&gt;Cosa mettiamo stasera nel minestrone.&lt;/h3&gt;
&lt;p&gt;Virtualizzato, potente, veloce (già quattro HDD e una buona cache sanno il fatto loro, per 20 dipendenti), che può crescere insieme all’azienda; ci vuol nulla, deployando tutto come VM.
Dentro mettetegli un fileserver, un mailserver, un proxy squid che lavora in whitelisting per alcuni e in blacklisting per altri (ah, già vedo i sorrisi del CEO!), ammenicoli per la VPN/firewall, un sistema ERP come OpenBravo. Fateli testare ed integrare bene almeno un annetto… con tutto l’hardware che venderete al corredo, sopratutto il sottosistema di stampa e i POS; lì, avete tonnellate di know-how.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Validate&lt;/strong&gt; le ultime incarnazioni di LibreOffice, magari anche con plugin proprietari per la conversione da ooXML (esistono eccome, e funzionano bene!), al resto pensa il motore LaTeX che gestisce l’output dall’ERP; niente rocket science, si tratta di scrivere un paio di parser da applicare a dei modelli, eventualmente personalizzabili.
Assomiglia molto al lavoro di integration che spesso viene demandato ai sysadmin o ai dbadmin.&lt;/p&gt;

&lt;h3 id=&quot;e-il-coccodrillo&quot;&gt;E il coccodrillo?&lt;/h3&gt;
&lt;p&gt;Riguardo i clients, fornite della roba ARM o MIPS che utilizza X over ethernet verso delle VM sul server; X11 funziona egregiamente in LAN, non molto in WAN. Qualora si dovesse scalare, SPICE ha fatto passi da gigante ed è abbastanza utilizzabile. Macchinette da 20 euro al pezzo, da rivendere a 150 con la grande O verde, stando ancora molto sotto quanto viene chiesto oggi per un thin client.&lt;/p&gt;

&lt;p&gt;Per i servers: i dual socket commodity x86 con le features RAS vanno già benissimo per poter sostenere la “responsabilità operativa” di un’intera azienda di queste dimensioni, senza far casini con storage di rete e quant’altro, che su questa fascia di prezzo minerebbero l’affidabilità dell’insieme (lo spiegavo qualche post fa). Nel settore c’è fermento nonostante la commoditization, sono parecchi i vendors che sgomitano: Huawei, dice nulla?. Volendo, se la cosa dovesse scalare diversamente, si potrebbe portare tutto &lt;em&gt;già oggi&lt;/em&gt; su ARM o POWER senza salti mortali.&lt;/p&gt;

&lt;h3 id=&quot;tutto-eo-niente&quot;&gt;Tutto E/O niente&lt;/h3&gt;
&lt;p&gt;Bisogna fornire il rack &lt;strong&gt;completo&lt;/strong&gt;, già precablato e labelizzato (mezzo rack dovrebbe bastare per la maggior parte delle PMI), includendo il poco networking, un NAS per i backup in situ (più un altro in remoto, o comunque altrove, che replica gli snapshots delle VM); un paio di UPS correttamente dimensionati, magari anche filtrati; la soluzione è pensata per aziende che &lt;strong&gt;non hanno&lt;/strong&gt; un comparto IT, non vogliamo che il primo ingegnere elettronico di turno ci metta le mani, no? &lt;/p&gt;

&lt;p&gt;Qualcosa che altri hanno già pensato di fare, ad esempio Dell con vStart e la stessa VMware con VCE, solamente a prezzi di un ordine di grandezza superiore. La differenza con questi giganti è la facilità di gestione per la PMI, che sarà molto scoraggiata dal mettere le mani su QEMU e combinar casini, piuttosto che farlo su HyperV o l’interfaccia web di vSphere; già, il minimalismo come baluardo, e contraltare degli infiniti databases, API e framework immensi che oggi si &lt;strong&gt;devono&lt;/strong&gt; usare anche per gestire installazioni su piccola scala.&lt;/p&gt;

&lt;p&gt;Otteniamo così un sistema centralizzatISSIMO, sul quale si può fornire assistenza top-down, che consuma poco ed usa le risorse (storage locale, sistema scale UP) in modo intelligente (containers, VMs che condividono la stessa golden image, networking quasi tutto interno al singolo nodo), e può soddisfare il 99% delle esigenze delle PMI che partono da zero, o quasi. Nessun casino con malware &amp;amp;co. (SELINUX è tuo amico), nessun aggiornamento idiota che blocca l’operatività. &lt;/p&gt;

&lt;p&gt;Qualora una VM client dovesse avere un problema, con le funzionalità standard di qualsiasi distro enterprise odierna è già possibile ricreare la macchina da un template (scriptato con Puppet ovviamente) in pochi SECONDI, da remoto con Mosh o SSH + DynDNS. Così, si può fornire assistenza remota senza mandare i sistemisti in situ anche sulla più misera delle ADSL (ho fatto esperienza pure sul 3G).
Alla bisogna, si fornisce anche la possibilità di collegarsi a delle VM Windows, e ci si può anche sobbarcare la conversione dei vecchi documenti da formato “Office” a ODF.&lt;/p&gt;

&lt;h3 id=&quot;ok-ma&quot;&gt;Ok, ma…&lt;/h3&gt;
&lt;p&gt;Fornire tutto ciò in comodato d’uso, un TOT al mese, gestendo l’hardware usato (che così si può riutilizzare fino a “fine vita”) non è una banalità, ma mi sembra raggiungibile con le cifre lette nell’articolo, in due-tre anni. Sempre meglio che morire di fame rimarchiando tablet.&lt;/p&gt;

&lt;p&gt;È antiquato, sembra un ritorno ai vecchi AS400? Sì, esatto. &lt;strong&gt;CHE DIFATTI, FUNZIONAVANO.&lt;/strong&gt;
Vedo ovunque un grande bisogno di ritorno a soluzioni più “commensurabili”, comprensibili, architetturalmente meno articolate, e che nascondano meno la loro complessità; in una parola: &lt;em&gt;semplici&lt;/em&gt; anche se non necessariamente &lt;em&gt;facili&lt;/em&gt;… dove &lt;em&gt;facile&lt;/em&gt; che è un concetto relativo: vi sembra “facile” utilizzare Metro per task avanzati o metter su un cluster di active directory perché il database potrebbe corrompersi random in qualsiasi momento? Ma, &lt;strong&gt;sopratutto&lt;/strong&gt; dover dialogare con sistemi che dipendono in modo assolutamente vincolante dal buon funzionamento di DNS&amp;amp;co. (cosa abbastanza fragile), la cui gestione viene spesso affidata al primo santone di tutto che “sa installare Windows”, e questo anche per installazioni da una decina di postazioni?&lt;/p&gt;

&lt;p&gt;Non credo che ci sia mai stato un momento più propizio per l’ingresso di una soluzione di questo tipo (Linux desktop e server, tutto virtualizzato a la “mainframe x86”), dati i pesanti colpi accusati da Microsoft ed un drammatico calo dei costi di storage e server di bassa gamma, insieme alla sostanziale scomparsa delle soluzioni prima denominate &lt;em&gt;midrange&lt;/em&gt; da questa fascia di mercato (ex system P, system i, AS400 ecc.); manca solamente un’azienda agile, che abbia voglia di fare il primo passo.&lt;/p&gt;

&lt;p&gt;Ah, mi dicono che il logo sia diventato &lt;em&gt;rosso&lt;/em&gt;, adesso.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;http://francescoprovino.com/Olivetti/&quot;&gt;La grande O nel cielo&lt;/a&gt; è stato originariamente pubblicato da Francesco Provino il &lt;a href=&quot;http://francescoprovino.com&quot;&gt;Francesco Provino&lt;/a&gt; su June 09, 2015.&lt;/p&gt;

  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[The birth and death of RAID]]></title>
  <link rel="alternate" type="text/html" href="http://francescoprovino.com/The_birth_and_death_of_RAID/" />
  <id>http://francescoprovino.com/The_birth_and_death_of_RAID</id>
  <published>2015-06-06T00:00:00+02:00</published>
  <updated>2015-06-06T00:00:00+02:00</updated>
  <author>
    <name>Francesco Provino</name>
    <uri>http://francescoprovino.com</uri>
    <email>me@francescoprovino.com</email>
  </author>
  <content type="html">
    &lt;p&gt;Le prime notizie relative al RAID risalgono alla fine degli anni ‘70, quando le macchine UNIX midrange iniziarono a dotarsi di quello che oggi chiameremmo “RAID Software”; prima c’erano solo sistemi per la correzione di errori in memoria, ma di tipo offline.&lt;/p&gt;

&lt;h2 id=&quot;pubblicit-progresso&quot;&gt;Pubblicità progresso&lt;/h2&gt;
&lt;p&gt;Fa sempre bene ricordare come il RAID non sia una soluzione che riguarda la &lt;strong&gt;sicurezza&lt;/strong&gt; dei dati: il RAID è una soluzione che riguarda la &lt;em&gt;continuità del servizio&lt;/em&gt;. Ovvero, un array RAID permette di &lt;em&gt;continuare a lavorare&lt;/em&gt; durante un guasto, ma è implicito che ci si debba immediatamente prodigare per sostituire il componente guasto e non si possa fare a meno di un sistema di backup.&lt;/p&gt;

&lt;p&gt;Il RAID non sostituisce il backup, &lt;strong&gt;mai&lt;/strong&gt;: sono due sistemi concettualmente ed operativamente diversi; se il RAID è online (cioè utilizzato per l’accesso ai dati di lavoro), e garantisce la continuità del servizio, il backup è invece offline, off-site e fornisce archiviazione, conservazione e sicurezza dei dati.
Il backup in genere è una soluzione di &lt;em&gt;disaster recovery&lt;/em&gt;, il RAID è &lt;em&gt;risk mitigation&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;scsi-golden-age&quot;&gt;SCSI Golden Age&lt;/h2&gt;
&lt;p&gt;L’utente medio ricorderà probabilmente i controller entry level Adaptec o LSI dei primi anni ‘90, nati principalmente per supplire allo scadente RAID software integrato in Windows… ancora oggi parecchio deficitario rispetto all’esemplare implementazione di &lt;strong&gt;md&lt;/strong&gt; su Linux.
Le tipiche configurazioni prevedevano RAID 5, tre-cinque dischi (rigorosamente &lt;em&gt;dispari&lt;/em&gt;, per agevolare il calcolo della parità)… fino all’inizio degli anni 2000, i dischi costavano parecchio e non c’erano alternative in quella fascia di prezzo.&lt;/p&gt;

&lt;p&gt;Inoltre, le CPU x86 erano ancora pressapoco dei giocattoli, che mal sopportavano l’overhead dei livelli RAID con parità. I SO avevano ancora una gestione delle code di I/O abbastanza primitiva; l’offloading del calcolo all’ASIC del controller era una manna dal cielo. Da metà degli anni ‘90 il RAID hardware in qualsiasi macchina server viene considerato praticamente obbligatorio, e in una decade diventa &lt;em&gt;commodity&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Ogni array che si rispetti ha i suoi dischi SCSI da 73Gb a 10kRPM, il RAID 5 &lt;em&gt;regge&lt;/em&gt; perché il fallimento dovuto ad &lt;a href=&quot;http://en.wikipedia.org/wiki/RAID#URE&quot;&gt;URE&lt;/a&gt; è abbastanza improbabile date le dimensioni degli HDD.
Da segnalare anche la diffusione nelle motherboard consumer dei cosidetti “&lt;em&gt;FakeRAID&lt;/em&gt;”, implementazioni puramente software e supportate quasi unicamente da Windows. Sono generalmente non troppo prestazionali o affidabili, e poco impiegate in ambito enterprise.&lt;/p&gt;

&lt;h2 id=&quot;per-dipingere-una-parete-grande-ci-vuole-un-pennello-grande&quot;&gt;Per dipingere una parete grande, ci vuole un pennello grande&lt;/h2&gt;
&lt;p&gt;Saltiamo avanti di due decenni, siamo negli anni 2010 (chissà che convenzione tireranno fuori riguardo queste decadi, al momento lo scrivo per esteso): i dischi raggiungono capacità di svariati Tb, il costo dello storage è in caduta libera, il fallimento per URE mette fuori dai giochi i livelli RAID con singola parità.&lt;/p&gt;

&lt;p&gt;Il RAID 10 viene universalmente adottato in ambito enterprise, affiancato dal RAID 6 o livelli proprietari (aventi comunque almeno doppia parità) per l’archiviazione massiva.
Assistiamo inoltre ad una ulteriore evoluzione del RAID software: le prestazioni delle CPU rendono &lt;strong&gt;md&lt;/strong&gt; più che adeguato per la maggior parte degli array-use_case; inoltre, con la comparsa di &lt;em&gt;ZFS&lt;/em&gt; l’utente può usufruire di un filesystem che fa anche RAID (con tripla parità!) e &lt;em&gt;volume management&lt;/em&gt; avanzato… permette anche di impostare dispositivi per il caching!
Ciononostante, il RAID hardware viene ancora preferito in sistemi di produzione per alcune caratteristiche avanzate:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;possibilità di fare caching con analisi &lt;em&gt;euristica&lt;/em&gt; dei blocchi più utilizzati su cache molto grandi (anche decine di Gb);&lt;/li&gt;
  &lt;li&gt;blind swap, ovvero sostituzione dei dischi a caldo e ricostruzione dell’array senza nessun altro intervento da parte dell’operatore (spostando la gestione dell’array dal system admin all’operatore hardware);&lt;/li&gt;
  &lt;li&gt;batterie interne, che anche in caso di totale failure dell’alimentazione permettono al controller di terminare le scritture o almeno memorizzarle su dispositivi a stato solido fino al successivo recovery;&lt;/li&gt;
  &lt;li&gt;replica remota su altri controller con latenze molto basse;&lt;/li&gt;
  &lt;li&gt;OS-agnosticità, tanto da poter essere montati su dispositivi come SAN, NAS, DAS ecc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Il RAID è una pratica ormai assolutamente standardizzata e &lt;strong&gt;implicita&lt;/strong&gt; in ogni installazione di un certo livello.&lt;/p&gt;

&lt;h2 id=&quot;and-thanks-for-all-the-bits&quot;&gt;…and thanks for all the bits&lt;/h2&gt;

&lt;p&gt;E allora, perché nel titolo parlo di &lt;em&gt;morte&lt;/em&gt; del RAID? 
La domanda da porsi è se il concetto di unità di storage in RAID (per come lo intendiamo oggi, assistito da un controller hardware in particolare) abbia ancora senso con l’avvento degli SSD di nuova generazione, per i seguenti motivi:&lt;/p&gt;

&lt;h4 id=&quot;prestazioni-del-bus&quot;&gt;Prestazioni del bus&lt;/h4&gt;
&lt;p&gt;Sfruttando le connessioni PCI-E (o, ultimamente, gli slot della &lt;a href=&quot;http://www-03.ibm.com/systems/x/options/storage/solidstate/exflashdimm/index.html&quot;&gt;RAM&lt;/a&gt;), gli SSD permettono prestazioni teoricamente equivalenti alle massime ottenibili da un controller RAID, poiché sfruttano lo stesso bus di sistema per comunicare con la cpu.&lt;/p&gt;

&lt;h4 id=&quot;parallelismoprestazioni&quot;&gt;Parallelismo/Prestazioni&lt;/h4&gt;
&lt;p&gt;Le maggiori prestazioni ottenuti dai controllers compiendo I/O in parallelo su dischi rotazionali, oggi sono replicabili leggendo o scrivendo in contemporanea (striping) da un numero &lt;em&gt;praticamente arbitrario&lt;/em&gt; di NAND, solamente “limitato dal controller”; questa volta, quello dell’SSD. &lt;/p&gt;

&lt;p&gt;Da qui la crescita esplosiva nelle prestazioni degli ultimi SSD messi in commercio, che arrivano a picchi di quasi 4Gb/s (GigaBYTE, non Bit) R/W, con latenze bassissime.
E se ci sono ancora obiezioni sulla capacità, basta guardare agli &lt;a href=&quot;http://www.fusionio.com/data-sheets/iomemory-sx300-atomic-series/&quot;&gt;ultimi ritrovati&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;parallelismoaffidabilit&quot;&gt;Parallelismo/Affidabilità&lt;/h4&gt;
&lt;p&gt;La maggior affidabilità del RAID di dischi rotazionali (RAID 10, ovviamente) è data dal poter eseguire letture e scritture in parallelo (stavolta, cloning) su “pezzi di hardware” distinti, e grazie ad uno strato software di recuperare eventuali fallimenti… esattamente ciò che viene fatto &lt;em&gt;NAND per NAND&lt;/em&gt; dagli attuali SSD enterprise, che spesso espongono una capacità effettiva minore (anche del 30%) per potere, grazie alla logica del controller, tenere alcuni settori &lt;em&gt;spare&lt;/em&gt; che generalmente vengono utilizzati come &lt;strong&gt;settori di parità&lt;/strong&gt; a la RAID con parità (multipla!).&lt;/p&gt;

&lt;p&gt;Questa architettura sembra funzionare molto bene per via dell’enorme numero di &lt;em&gt;nodi&lt;/em&gt; per stripes e il grande “dominio di parità”; il controller riesce a tenere conto con discreta precisione dello stato di salute delle singole componenti, e generalmente rimpiazza le NAND che si avvicinano a fine vita con quelle precedentemente tenute &lt;em&gt;a riposo&lt;/em&gt; prima che ci possa essere un sostanziale degradamento di prestazioni o affidabilità.
Un esempio di queste funzionalità viene molto chiaramente descritto &lt;a href=&quot;http://www.fusionio.com/blog/adaptive-flashback&quot;&gt;qui&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;so-what&quot;&gt;So what?&lt;/h1&gt;
&lt;p&gt;A mio parere, ci avviciniamo ad un cambio di paradigma nel quale il supporto di memorizzazione a stato solido sarà affidabile e prestazionale quanto un controller RAID, rendendone di fatto superfluo l’utilizzo, limitatamente almeno allo storage locale.
La battaglia si sta già svolgendo, specialmente fra gli algoritmi per il wear-leveling e livelli di RAID-ridondanza “interni”; ne parlano molto gli ultimi papers di IBM sui loro nuovi storage all-flash e altri di Intel e FusionIO.&lt;/p&gt;

&lt;p&gt;Costano troppo? Space-wise, ancora per qualche anno. IOPS-wise, c’è già stato il sorpasso. Per fare gli IOPS di un SSD enterprise ci vogliono una batteria di dischi SAS più un controller RAID con una cache mica da ridere… e se non li puoi hostare dentro la macchina singola, ti serve anche una SAN, che presa da sola peggiora l’affidabilità del sistema. Altrimenti ne servono due, con due switches FC, HBA ridondanti, ecc; ed ecco che la soluzione con storage locale torna ad essere concorrenziale sia sul prezzo che nella semplicità di gestione, magari assistita da una replica block-level.&lt;/p&gt;

&lt;p&gt;Naturalmente, lo use-case che immagino è quello di workload mission-critical; non certo di quello di consolidamento dello storage nel quale latenza, prestazioni pure e semplicità dell’infrastruttura passano in secondo piano.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;http://francescoprovino.com/The_birth_and_death_of_RAID/&quot;&gt;The birth and death of RAID&lt;/a&gt; è stato originariamente pubblicato da Francesco Provino il &lt;a href=&quot;http://francescoprovino.com&quot;&gt;Francesco Provino&lt;/a&gt; su June 06, 2015.&lt;/p&gt;

  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[L'insostenibile leggerezza dello specchio]]></title>
  <link rel="alternate" type="text/html" href="http://francescoprovino.com/why_dslr_arent_going_anywhere/" />
  <id>http://francescoprovino.com/why_dslr_arent_going_anywhere</id>
  <published>2015-05-23T00:00:00+02:00</published>
  <updated>2015-05-23T00:00:00+02:00</updated>
  <author>
    <name>Francesco Provino</name>
    <uri>http://francescoprovino.com</uri>
    <email>me@francescoprovino.com</email>
  </author>
  <content type="html">
    &lt;p&gt;Si parlava ovunque della imminente scomparsa delle DSLR a favore delle mirrorless; passato l’hype (che aveva preso un po’ anche me, non lo nego) del mercato e dell’opinionista fotografico medio, possiamo inquadrare meglio il topic dal punto di vista dell’utilizzatore prosumer/professionale.
A mio parere, le DSLR sono qui per restare. Ancora per molto, molto tempo.
Ne sono così convinto, che una delle mie ultime acquisizioni è stata proprio un’ottica manual focus per DSLR.
Proviamo a capire perché.&lt;/p&gt;

&lt;h2 id=&quot;autonomia&quot;&gt;Autonomia&lt;/h2&gt;
&lt;p&gt;Una DSLR avrà sempre un’autonomia superiore a parità di sensore rispetto ad una mirrorless, perché può tenere attivo il sensore soltanto poche frazioni di secondo versus tutto il tempo che serve per comporre l’inquadratura e mettere a fuoco. Ovvero, resta con una buona fetta dell’elettronica “spenta” durante buona parte dell’utilizzo; al contrario, in una mirrorless il sensore deve essere sempre acceso per focheggiare, misurare la
luce ecc.
Questo inoltre riscalda il sensore, lo rovina prima, crea rumore termico, richiede batterie più grandi.&lt;/p&gt;

&lt;h2 id=&quot;dimensioni&quot;&gt;Dimensioni&lt;/h2&gt;
&lt;p&gt;Batterie più grandi vogliono dire dimensioni più grandi e potrebbe anche succedere che una DSLR, a parità di autonomia, abbia dimensioni complessive più piccole di una mirrorless (si recupera lo spazio mirabox con il supplemento di batteria). La cosa potrebbe andare bene per macchine poco professionali da 300 scatti a carica, ma per qualsiasi impiego di reportage, il gioco si fa duro…&lt;/p&gt;

&lt;p&gt;Non dimentichiamo inoltre che le dimensioni complessive sono influenzate anche dai comandi: a parità di
numero di ghiere e pulsanti, la cui numerosità e dimensionamento è dettata da esigenze operative e fisiologiche precise, non vedo particolari vantaggi dimensionali delle mirrorless su un corpo macchina professionale.
Inutile girarci attorno, ma un corpo PRO &lt;strong&gt;deve&lt;/strong&gt; avere delle dimensioni simili alle attuali ammiraglie Nikon e Canon (D4s e 1Dx) per consentire una impugnatura salda e comoda anche in posizione verticale e con ottiche voluminose e pesanti.&lt;/p&gt;

&lt;h2 id=&quot;corredo&quot;&gt;Corredo&lt;/h2&gt;
&lt;p&gt;Bisogna considerare che il corpo macchina è spesso una componente dimensionalmente minoritaria rispetto a tutto il resto dell’attrezzatura professionale, pensiamo a luci ed ottiche… spesso questo “&lt;em&gt;schiacciante&lt;/em&gt;” vantaggio a favore delle mirrorless è stato eccessivamente enfatizzato dal marketing, ma non dimentichiamo che esistono delle precise motivazioni ottiche per le quali un 300 f2.8 non può essere parecchio più piccolo degli attuali.&lt;/p&gt;

&lt;h2 id=&quot;qualit-delle-ottiche&quot;&gt;Qualità delle ottiche&lt;/h2&gt;
&lt;p&gt;Esistono vantaggi reali nell’eliminare il box specchio dal punto di vista del design ottico, sopratutto nel design di ottiche grandangolari. La loro focale infatti spesso è minore delle dimensioni fisiche occupate dallo specchio; ovvero, dovremmo ritrovarci con il nocciolo ottico &lt;strong&gt;dentro&lt;/strong&gt; lo specchio… la cosa viene risolta (vado molto a spanne) disegnando un grandongolare standard e aggiungendo un “telescopio” che permette la corretta formazione dell’immagine sul sensore anche se &lt;strong&gt;tutta&lt;/strong&gt; l’ottica dista dal sensore parecchio più della distanza focale. Questo vantaggio esiste solamente per focali dai 50mm in giù; già sopra i 35mm all’incirca, (lo spazio retrofocale occupato dallo specchio) gli schemi ottici sono abbastanza equivalenti.&lt;/p&gt;

&lt;p&gt;Inoltre, i sensori digitali hanno messo in luce un limite dei grandangolari simmetrici: per ovvie motivazioni ottiche, i raggi ai bordi del circolo di copertura arrivano &lt;em&gt;parecchio&lt;/em&gt; inclinati sul sensore. Sembrano esserci problemi con CCD e CMOS rispetto alla pellicola: se quest’ultima offriva una superficie sensibile praticamente piatta (anche se sul colore avremmo potuto vedere qualche shift dato dalla profondità dei layers), i sensori digitali possiamo immaginarli con pixel formati da scatole quadrate senza una faccia (dalla quale entra la luce) e la superficie sensibile sulla faccia opposta.&lt;/p&gt;

&lt;p&gt;Va da sè che parte dell’informazione luminosa si perda sulle facce &lt;em&gt;non sensibili&lt;/em&gt; al crescere dell’angolo con il quale incide la radiazione. A riguardo, Leica/Dalsa sembrano avere risolto la problematica aggiungendo delle microlenti (stile Fresnel) sulla superficie del sensore, che unite ad un profiling software di ogni lente fanno un ottimo lavoro. Comunque, fino a 20mm gli schemi retrofocus del mondo reflex non si difendono malaccio, basti pensare a quelle meraviglie degli Zeiss ZF.&lt;/p&gt;

&lt;h2 id=&quot;messa-a-fuoco&quot;&gt;Messa a fuoco&lt;/h2&gt;
&lt;p&gt;La precisione del live view confrontato con il mirino ottico senza magnificazioni (0.8x rispetto all’ottica 50mm) è leggermente a favore del mirino digitale, che offre il lusso del di poter cambiare l’ingrandimento alla bisogna; mi chiedo però se sia realmente possibile focheggiare un 135mm a mano libera guardando i pixel 4:1… Un buon mirino ottico con la giusta magnificazione (io uso il DG-2 su Nikon, prima avevo un KatzEye sulla digitale), può ancora vincere in un contesto di reportage d’azione.&lt;/p&gt;

&lt;p&gt;Ovviamente, per qualsiasi impiego dove la precisione pixel-level è un requisito, il live view è comunque necessario.
Tutti i corpi reflex attuali offrono il live view a richiesta, ne segue che per impieghi di tipo &lt;strong&gt;studio&lt;/strong&gt; le due piattaforme sono abbastanza interscambibili. Inoltre, avere in più il mirino ottico &lt;em&gt;sempre attivo&lt;/em&gt; offre una visione più rilassante, disponibile anche a macchina spenta.&lt;/p&gt;

&lt;h2 id=&quot;inerzia&quot;&gt;Inerzia&lt;/h2&gt;
&lt;p&gt;Ci sono interi standard industriali che si basano sulla baionetta di certe reflex (pensiamo all’attrezzatura scientifica in montatura Nikon), oltre al workflow della quasi totalità dei professionisti sulla piazza.
Tonnellate di accessori, supporti, un intero ecosistema economico gravita attorno alla tecnologia delle reflex; come per certe tecnologie informatiche… avete presente il COBOL? Dagli anni ‘80 ad oggi l’avranno dato per morto una ventina di volte; fatevi un giro su LinkedIN e vedete quanto siano richiesti oggi i programmatori COBOL. Il legacy è una brutta bestia, ma è anche dove le aziende investono, è la base sulla quale costruiscono il loro business.&lt;/p&gt;

&lt;h2 id=&quot;alcune-noncuranze&quot;&gt;Alcune noncuranze&lt;/h2&gt;
&lt;p&gt;Non per problemi tecnologici o architetturali, ma ancora il segmento mirrorless presenta delle lacune eccellenti:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Niente corpi professionali al momento, e non sembrano in arrivo rapidamente. Ricordiamo che &lt;em&gt;no corpi pro&lt;/em&gt; &lt;strong&gt;=&amp;gt;&lt;/strong&gt; &lt;em&gt;no
ottiche pro&lt;/em&gt;. La rigidezza è tutto.&lt;/li&gt;
  &lt;li&gt;Nessun modello attuale ha un sistema di flash TTL maturo, o almeno usabile in contesti produttivi.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;User base&lt;/em&gt; piccola, e quindi nessun grosso investimento in massiccio in &lt;em&gt;R&amp;amp;D&lt;/em&gt;; il mercato langue, non ci sono grandi novità all’orizzonte. Paradossalmente, è molto più vivace il segmento dei dorsi digitali medio formato, che stanno finendo di soppiantare il 4x5.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Quindi, tranquilli: &lt;strong&gt;DSLRs aren’t going anywhere&lt;/strong&gt;.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;http://francescoprovino.com/why_dslr_arent_going_anywhere/&quot;&gt;L&#39;insostenibile leggerezza dello specchio&lt;/a&gt; è stato originariamente pubblicato da Francesco Provino il &lt;a href=&quot;http://francescoprovino.com&quot;&gt;Francesco Provino&lt;/a&gt; su May 23, 2015.&lt;/p&gt;

  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Sulla mistica dello storage enterprise]]></title>
  <link rel="alternate" type="text/html" href="http://francescoprovino.com/enterprise-storage/" />
  <id>http://francescoprovino.com/enterprise-storage</id>
  <updated>2015-05-21T00:00:00-00:00</updated>
  <published>2014-10-27T00:00:00+01:00</published>
  
  <author>
    <name>Francesco Provino</name>
    <uri>http://francescoprovino.com</uri>
    <email>me@francescoprovino.com</email>
  </author>
  <content type="html">
    &lt;p&gt;Quello dello storage non-consumer è sicuramente uno dei settori dell’IT più floridi per quanto riguarda la nascita di miti e leggende: cosa favorita, oltre dal marketing dei big players, dall’oggettiva complessità di alcuni concetti in gioco e dalla diffusa ignoranza degli uomini-IT in merito.&lt;/p&gt;

&lt;p&gt;Vediamo di semplificare un po’, dando delle descrizioni “operative”.&lt;/p&gt;

&lt;h2 id=&quot;das&quot;&gt;DAS&lt;/h2&gt;
&lt;p&gt;Né più né meno dello storage interno del vostro server, ma ospitato in una enclosure esterna; da vedere come una “unità di espansione dischi” o “moltiplicatore di porte SAS esterno”. Generalmente il collegamento alle macchine avviene tramite cavi SAS (gli stessi che collegano i dischi locali), lo storage viene visto esattamente come uno o più dischi interni alla macchina. &lt;/p&gt;

&lt;p&gt;Come un qualsiasi controller SAS interno, sono muniti di funzionalità RAID e permettono di esporre partizioni, “array” dell’aggregato di dischi fisici, presentati alla macchina come normalissimi dispositivi a blocchi AKA dischi interni.&lt;/p&gt;

&lt;h2 id=&quot;san&quot;&gt;SAN&lt;/h2&gt;
&lt;p&gt;È qui che si concentrano la maggior parte degli equivoci, quindi diciamolo subito: la SAN non è altro che un DAS esposto ai servers tramite un protocollo di rete (iSCSI, FC, FCoE). Fine.
Più precisamente la Storage Area Network è un insieme di dispositivi, composta oltre dalla parte al quale viene generalmente attribuito il nome SAN, anche dagli switch e dagli HBA presenti sui servers; è giustappunto un &lt;strong&gt;network&lt;/strong&gt;, non un singolo dispositivo.&lt;/p&gt;

&lt;p&gt;È quindi possibile fare switching e routing del flusso di dati riguardanti lo storage, oltre a poter utilizzare il tutto in direct-attach similmente al DAS.
Cosa? Routing dello storage? Pazienza Iago, pazienza.&lt;/p&gt;

&lt;h2 id=&quot;nas&quot;&gt;NAS&lt;/h2&gt;
&lt;p&gt;Questo lo conosciamo bene tutti; un NAS è un fileserver che permette la condivisione dello storage a livello del filesystem, ovvero incorpora tutto lo stack necessario a presentare ai servers files e cartelle. Questo è l’unico dispositivo fra quelli presi in esame a permettere l’accesso allo storage a livello di files e non di blocchi; cioè, non è permesso accedere direttamente all’array di dischi fisici per partizionarlo, formattarlo ecc. Inoltre è l’unico, e sottolineo l’unico, ad incorporare la logica necessaria a gestire l’utilizzo in concorrenza di più macchine ad uno stesso pezzo di storage.&lt;/p&gt;

&lt;h2 id=&quot;e-allora&quot;&gt;E allora?&lt;/h2&gt;
&lt;p&gt;Come, la SAN non serviva per “condividere lo storage” fra più macchine? NO.
La SAN nasce principalmente per semplificare e rendere più efficiente la gestione dello spazio su disco di installazioni molto dense con parecchi servers, poiché è parecchio più semplice assegnare una LUN ad un server piuttosto versus spostare fisicamente (con ricostruzione array e quant’altro) dischi fra più macchine. In questo modo, è possibile assegnare dinamicamente “dischi” di dimensione variabile al server, senza interventi fisici e interruzioni dell’operatività: il punto che si possa fare su più macchine contemporaneamente, condividendo i dischi fisici, è la ragion
d’essere della SAN. &lt;/p&gt;

&lt;p&gt;In realtà, anche il DAS può fornire funzionalità di questo tipo se le macchine sono poche e abbastanza vicine allo storage, collegando direttamente i servers allo storage.
Nella caso della SAN, sia essa FC, FCoE o iSCSI, è addirittura possibile collegare lo storage e i servers a degli switch e persino a dei router in configurazioni simili a quelle di una tradizionale LAN, che permettono ad esempio di realizzare configurazioni che hanno particolari caratteristiche di resistenza ai guasti (utilizzando più SAN in replica, ad esempio).&lt;/p&gt;

&lt;p&gt;Andiamo oltre adesso; collegate due macchine fisiche alla stessa LUN di una SAN (con dei dati all’interno, magari): vi ritroverete con un filesystem irrimediabilmente corrotto dopo qualche secondo, e la totale distruzione dei dati sarebbe cosa inevitabile dopo pochi tentativi di scrittura.
Perché? Perché collegare una SAN a due macchine, è come collegare un ideale hard disk fisico con due cavi SAS a diversi computers: alla prima operazione contemporanea, vi ritrovate con un ammasso di bit insignificanti.
C’è un solo modo per gestire un hard disk condiviso fra due macchine: un filesystem distribuito, detto anche &lt;em&gt;clusterizzato&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;san--file-sharing&quot;&gt;SAN != File Sharing&lt;/h2&gt;
&lt;p&gt;L’errata considerazione della SAN come “storage di files condiviso” a mio parere nasce dalla grande facilità d’uso di VMFS di VMware, che permette l’uso “trasparente” della SAN, presentando gli array agli utenti proprio come farebbe un NAS, cioè come spazio formattato nel quale è possibile effettuare operazioni in concorrenza sui files. Ma attenzione: come nel caso del NAS, è il filesystem che si occupa di gestire la concorrenza, questo nulla ha a che vedere con le caratteristiche della SAN. Provate a configurare un filesystem clustered come GPFS o GFS, se volete capire profondamente come funzioni la cosa; è sempre bene sporcarsi un po’ le mani per arrivare ad una comprensione piena di certi meccanismi.&lt;/p&gt;

&lt;h2 id=&quot;performance&quot;&gt;Performance&lt;/h2&gt;
&lt;p&gt;La tipologia di storage più performante in assoluto continua ad essere quello interno ai servers, ancor di più con il recente affermarsi di ssd PCI-E e memory-channel. Lo storage di rete, sia
esso SAN o NAS (e in una certa misura anche il DAS) è comunque limitato dall’overhead del protocollo di rete e dalla sua larghezza di banda.
L’ultima versione del FC quota 16Gbit/s, appena uscito e dai prezzi folli… Il PCI-E 3.0 16x fa circa 126Gbit/s, oggi, per slot, e sono già uscite le specifiche del 4.0 che avrà esattamente il doppio di banda; cambia poco negli ordini di grandezza se consideriamo iSCSI.
Il DAS ha generalmente poco overhead, scala in termini di multipli interi di porte SAS a 12Gbit/s.&lt;/p&gt;

&lt;h1 id=&quot;keep-it-simple-stupid&quot;&gt;Keep it simple, stupid!&lt;/h1&gt;
&lt;p&gt;Tutto questo può essere letto come un invito a semplificare il più possibile la topologia dello storage: si guadagna in prestazioni, si risparmia,  si ottiene un’affidabilità maggiore; la crescita di complessità può essere giustificata solamente quando non è assolutamente possibile soddisfare i requisiti progettuali senza aggiungere componenti o layer di astrazione.&lt;/p&gt;

&lt;p&gt;In generale, lo storage locale è sempre da preferire a tutte le altre alternative; la “catena cinematica” è la più corta, ciò porta a meno connettori/interfacce che possono guastarsi (o fare contatto intermittente, che è una delle cause più comuni del fail nei raid con parità), minore latenza e
prestazioni massime, oltre che semplicità di gestione.
La crescita di dimensioni dello storage può urtare i limiti fisici del singolo server, ed ecco che abbiamo bisogno di un DAS per la scalabilità.
Gli ambiti dove è opportuno utilizzare NAS e SAN enterprise dopo l’avvento dei meccanismi di replica software block-level e file-level, sono sempre più ristretti; in particolare, nel caso della SAN è necessario avere del personale iniziato ai misteri della condivisione block-level ed una
infrastruttura abbastanza ridondante, cosa che spesso si traduce in esborsi non indifferenti e difficilmente giustificabili nel mondo delle PMI.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;http://francescoprovino.com/enterprise-storage/&quot;&gt;Sulla mistica dello storage enterprise&lt;/a&gt; è stato originariamente pubblicato da Francesco Provino il &lt;a href=&quot;http://francescoprovino.com&quot;&gt;Francesco Provino&lt;/a&gt; su October 27, 2014.&lt;/p&gt;

  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Sopravvivere al velociraptor che cancella la tua tesi di laurea lanciando banane]]></title>
  <link rel="alternate" type="text/html" href="http://francescoprovino.com/git-faidate/" />
  <id>http://francescoprovino.com/git-faidate</id>
  <updated>2015-05-21T00:00:00-00:00</updated>
  <published>2014-09-15T00:00:00+02:00</published>
  
  <author>
    <name>Francesco Provino</name>
    <uri>http://francescoprovino.com</uri>
    <email>me@francescoprovino.com</email>
  </author>
  <content type="html">
    &lt;p&gt;In questi giorni c’è stato tanto rumore mediatico riguardo alla violazione di account iCloud contenenti dati personali, e non sono mancate brecce in altri noti sistemi poco tempo addietro.&lt;/p&gt;

&lt;p&gt;I sistemi cloud proposti al mercato consumer per l’archiviazione dei dati da qualche altra parte hanno conosciuto una crescita incredibile negli ultimi anni, grazie e sopratutto al mercato mobile che ha posto l’accento sulla possibilità di guasti/furti del dispositivo: &lt;strong&gt;un cellulare è intrinsecamente più rubabile e danneggiabile di un PC desktop&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Mi sembra incredibile e sopratutto &lt;em&gt;inaccettabile&lt;/em&gt; che a 42 (!) anni dalla nascita di &lt;strong&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Source_Code_Control_System&quot;&gt;SCCS&lt;/a&gt;&lt;/strong&gt; si possano ancora perdere dei dati per l’ignoranza e/o l’incuria dell’operatore; ho visto parecchi miei conoscenti disperarsi di fronte a files corrotti, modifiche involontarie ma ormai salvate…&lt;/p&gt;

&lt;p&gt;Gli attuali sistemi di cloud storage come Dropbox, iCloud, Google drive ed altri (mi riferisco sempre a prodotti consumer) limitano molto la problematica, ma permangono delle criticità.&lt;/p&gt;

&lt;h4 id=&quot;privacy&quot;&gt;Privacy&lt;/h4&gt;
&lt;p&gt;Dove sono i miei dati? Chi ha i miei dati? Qualcuno fa analisi statistica/rivende metadati sui miei files? È possibile che io non possa più fisicamente accedere ai miei dati?&lt;/p&gt;

&lt;h4 id=&quot;limitazionicosti&quot;&gt;Limitazioni/Costi&lt;/h4&gt;
&lt;p&gt;Molti servizi offrono account gratuiti, ma in genere lo spazio disponibile è parecchio limitato… inoltre, vengono imposte delle limitazioni come il numero di repliche, la dimensione massima dei files, la tipologia di client (pensate ad iCloud!), l’accessibilità e la completa gestione gerarchica delle informazioni memorizzate. Esistono servizi enterprise-grade che superano buona parte di queste problematiche, ma i costi sono spesso proibitivi; Amazon S3 in questo è forse il miglior compromesso.&lt;/p&gt;

&lt;h4 id=&quot;condivisione&quot;&gt;Condivisione&lt;/h4&gt;
&lt;p&gt;La possibilità di far partecipare altri utenti al proprio repository di files è spesso parecchio limitata, a meno di non condividere direttamente l’account (ORRORE!). In generale, questi servizi si prestano poco a lavori in team perché non hanno modo di gestire modifiche concorrenti ad uno stesso file, spesso è necessario fare una copia locale delle informazioni interessate e poi processare nuovamente tutto a cose fatte… parecchio inefficiente! Si può fare di meglio.&lt;/p&gt;

&lt;h2 id=&quot;retrospettiva&quot;&gt;Retrospettiva&lt;/h2&gt;
&lt;p&gt;La mia risposta a questi requirements, viene dal passato: GIT, SSH, un po’ di shell aliasing. Strumenti affidabili, collaudati da generazioni di sviluppatori nel tempo, e sopratutto adatti ad un uso professionale… che oggi possiamo utilizzare anche per esigenze personali, dati i giganteschi passi avanti fatti da elaboratori alla portata di tutti. &lt;/p&gt;

&lt;p&gt;È molto significativo notare come si spaccino per &lt;em&gt;novità&lt;/em&gt; delle conquiste tecnologiche vecchiotte: il “cloud computing” nasce negli anni ‘60 con i mainframe IBM (avete presente &lt;em&gt;tn3270&lt;/em&gt; che accede ad ISPF? No?), i sistemi di controllo versione datano prima del 1975, telnet era disponibile già nel ‘68. 
Oggi è tutto parecchio più comodo, maturo e sicuro; il problema è semmai che l’allargamento della base di utenza anche ad analfabeti (non solo) informatici ha portato ad un deciso livellamento verso il basso delle interfacce utente, che richiedono sempre meno apprendistato e al contempo nascondono la grandissima parte delle tecnologie sottostanti alle finestre sbrilluccicose.&lt;/p&gt;

&lt;h2 id=&quot;requisiti&quot;&gt;Requisiti&lt;/h2&gt;
&lt;p&gt;Parlando di GIT, molti sviluppatori che mi leggeranno lo assoceranno al servizio GitHub; bene, quel che propongo io e di fare quello che fa GitHub lato server: &lt;strong&gt;diventare&lt;/strong&gt; GitHub, diventare il servizio, per avere pieno controllo sul posizionamento e la gestione dei nostri dati.&lt;/p&gt;

&lt;p&gt;Ecco la lista della spesa:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Due o più macchine con sistema POSIX o quasi-POSIX (Linux, UNIX, BSD, Mac OS X vanno benissimo); se siete dei temerari, anche Windows con CGYWIN. Nelle macchine dovranno essere installati ssh server e client, oltre ad ovviamente GIT ed una shell POSIX o similare a vostra scelta (io uso ZSH). &lt;/li&gt;
  &lt;li&gt;Una configurazione del network che vi permetta di raggiungere mutuamente le macchine su una porta a vostra scelta, anche attraverso NAT e reindirizzamenti vari va bene. Anzi, è consigliato: cambiate la porta di default per ssh. Fatelo. Punto. Riconfigurate le regole del firewall di conseguenza. &lt;/li&gt;
  &lt;li&gt;La capacità di non cominciare a scrivermi commenti stile “cosa è Linux?”, “non ho mai usato GIT, come si fa un commit? Cosa è un branch?”, “Ma io ho android”, “eh la peppa, io uso razzomissileOS e funziona tutto più meglio assai di quello che scrivi tu”: per informarvi su queste cose ci sono DOC e wiki ufficiali, io sto scrivendo di una metodologia per combinare insieme degli strumenti in un determinato scenario… per creare uno strumento nuovo.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Che lo spirito del RTFM vi accompagni sempre.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;uno-sguardo-dinsieme&quot;&gt;Uno sguardo d’insieme&lt;/h2&gt;
&lt;p&gt;Supposto quindi che sappiate usare GIT e siate anche dei sysadmin UNIX/Linux discretamente in allenamento, passiamo alla descrizione di alto livello di ciò che faremo. 
Presa una cartella contenente dei files nella nostra macchina, l’idea è che grazie a GIT ogni cambiamento del quale faremo un “commit” verrà registrato come “istantanea” di tutti i file presenti nella cartella (sto semplificando, possiamo aggiungere file che si trovano ovunque ovviamente): questa istantanea sarà anche corredata di un commento esplicativo dei cambiamenti effettuati, così da avere una storyline di tutto il nostro progetto.&lt;/p&gt;

&lt;p&gt;Inoltre, ed è questo il pezzo interessante, tutto questo repository contenente sia i file all’ultima versione sia tutte le versioni degli snapshots precedenti all’attuale sia tutti i commenti esplicativi alle varie revisioni, verrano replicati su &lt;em&gt;N&lt;/em&gt; macchine remote. Naturalmente, sarà anche possibile clonare tutto il repository da queste macchine per generare sia delle nuove cartelle di lavoro, sia dei nuovi repository master dai quali poter clonare tutto, ecc ecc. E questo, su qualsiasi dispositivo che abbia GIT ed accesso ad uno qualsiasi fra i servers. &lt;/p&gt;

&lt;p&gt;La connessione fra server e client, sulla quale opererà GIT, verrà incapsulata dentro il protocollo SSH utilizzato tramite scambio di chiavi asimmetrico di chiavi RSA (niente ID-password, grazie!). E tutta questa procedura verrà automatizzata, in modo da ridursi a un semplice comando, quantomeno per l’upload dei cambiamenti; leggi: “per pararsi il culo da perdite di dati”. 
Essendo il flusso di dati criptato tramite RSA, a meno di non fare delle fesserie nella config e di cambiare periodicamente le chiavi RSA (la crittografia asimmetrica è soggetta ad attacchi di tipo statistico, se le chiavi si usano a lungo), il sistema è utilizzabile anche da sistemi separati dalla WAN (su internet, ecco). Pensate al computer di casa e quello dell’ufficio, per esempio. O un altro pc da qualche altra parte del mondo, cambia nulla.&lt;/p&gt;

&lt;h2 id=&quot;dettagli-implementazione&quot;&gt;Dettagli implementazione&lt;/h2&gt;
&lt;p&gt;Passiamo alla realizzazione pratica: chiameremo &lt;strong&gt;A&lt;/strong&gt;-server la macchina server e &lt;strong&gt;B&lt;/strong&gt;-client la macchina client (indicherò con &lt;strong&gt;A&lt;/strong&gt;-server e &lt;strong&gt;B&lt;/strong&gt;-client anche gli IP/nomi_dns delle macchine): il server conterrà il repo sul quale pusheremo le modifiche, il nostro backup insomma, che potremmo anche clonare in altre macchine; il repository sul server sarà di tipo &lt;strong&gt;bare repo&lt;/strong&gt;, cioè conterrà i files codificati nei vari snapshots, ma nessuna cartella di lavoro per l’utente.&lt;/p&gt;

&lt;p&gt;Il client, oltre alla propria copia locale del repository, contenente tutto quanto è presente nel &lt;strong&gt;bare repo&lt;/strong&gt; (ma nella cartella locale nascosta .git), e ANCHE la cartella di lavoro (che tecnicamente è una copia dell’ultimo snapshot).
Usiamo repository &lt;strong&gt;bare&lt;/strong&gt; sul server per risparmiare spazio manca l’ulteriore clone dell’ultimo snapshot, detto “working tree”. &lt;/p&gt;

&lt;h4 id=&quot;warning&quot;&gt;Warning!&lt;/h4&gt;
&lt;p&gt;Questo non è un howto per utenti della prima ora, quindi molti passaggi che sono dipendenti dall’implementazione e del vostro sistema operativo verranno omessi: descrivo &lt;strong&gt;COSA&lt;/strong&gt; fare, ma non &lt;strong&gt;COME&lt;/strong&gt; fare; se avete letto una RFC nella vostra vita (o un libro di analisi matematica), non dovreste avere problemi.&lt;/p&gt;

&lt;h3 id=&quot;ssh-pairing&quot;&gt;SSH pairing&lt;/h3&gt;
&lt;p&gt;Per prima cosa, dobbiamo permettere alle due macchine di comunicare fra loro, naturalmente via ssh, senza dover inserire ogni volta username e password: a tale scopo, permetteremo il collegamento tramite pairing di chiavi RSA. Creiamo le chiavi sul client; accediamo ad essa e nel terminale digitiamo:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-css&quot; data-lang=&quot;css&quot;&gt;&lt;span class=&quot;nt&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;@B-client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;ssh-keygen&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;rsa&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;L’output confermerà la creazione. Creiamo quindi la cartella di destinazione sul server&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-css&quot; data-lang=&quot;css&quot;&gt;&lt;span class=&quot;nt&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;@B-client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;ssh&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;@A-server&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;.ssh&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;e trasferiamo la chiave appena creata&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-css&quot; data-lang=&quot;css&quot;&gt;&lt;span class=&quot;nt&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;@B-client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;.ssh&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;id_rsa&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;.pub&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;ssh&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;@A-server&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;cat &amp;gt;&amp;gt; .ssh/authorized_keys&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;assegnando i permessi corretti&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-css&quot; data-lang=&quot;css&quot;&gt;&lt;span class=&quot;nt&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;@B-client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;ssh&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;@A-server&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;chmod 700 .ssh; chmod 640 .ssh/authorized_keys&amp;quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;verificate che sia possibile effettuare il login senza inserire credenzialia.
### Creazione dei repo
Creiamo quindi il repo in una cartella della macchina A-server; dopo esserci loggati in essa e aver creato la cartella /path/to/repo_server/, eseguiamo:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-css&quot; data-lang=&quot;css&quot;&gt;&lt;span class=&quot;nt&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;@A-server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;init&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--bare&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;repo_server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Questo sarà il nostro repository remoto. La configurazione sul server, ammesso di aver configurato correttamente ssh, firewall e il resto del networking, finisce qui… quindi, passiamo sul client! Creiamo il repository sul client, esattamente come fatto sul server:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-css&quot; data-lang=&quot;css&quot;&gt;&lt;span class=&quot;nt&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;@B-client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;init&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;repo_client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;e adesso, recidiamo il nodo gordiano: aggiungiamo l’origine remota al nostro repository. Ciò risponde alla domanda, “dove verrano mandati dati” da parte del 
client (che, ricordiamolo, è il sistema sul quale lavoriamo e del quale vogliamo avere un backup distribuito). Notare che nella riga sottostante sto usando una porta diversa dalla standard per ssh:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-css&quot; data-lang=&quot;css&quot;&gt;&lt;span class=&quot;nt&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;@B-client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;remote&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;A-server&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;ssh&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;://&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;@A-server&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;:60001&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;repo_server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Adesso proviamo a creare un file, fare un commit e poi l’output di&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-css&quot; data-lang=&quot;css&quot;&gt;&lt;span class=&quot;nt&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;@B-client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;push&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;A-server&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;dovrebbe confermare il funzionamento di quanto configurato, trasferendo gli elementi dal repo locale a quello remoto. Anche git status da ora in avanti terrà traccia dello status del repository remoto, segnalandovi quandi commit non avete ancora uploadato ecc. Una ulteriore conferma può essere data provando a clonare il repository remoto in locale:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-css&quot; data-lang=&quot;css&quot;&gt;&lt;span class=&quot;nt&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;clone&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;@A-server&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;:60001&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;repo_server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;automazione&quot;&gt;Automazione&lt;/h3&gt;
&lt;p&gt;Adesso che abbiamo un repository distribuito, possiamo aggiungere altri nodi-server o iniziare a cooperare con altri soggetti (anche non in LAN!) utilizzando il bare-repo come piattaforma per sviluppare qualsiasi progetto; ma sopratutto, possiamo rendere più ergonomico il funzionamento del sistema con dei piccoli aliasing (da mettere nel .bashrc, o ciò che usa la vostra shell in proposito) ad esempio possiamo syncare dei repo multipli remoti e/o locali, reindirizzando l’output dell’avvenuta (o meno) sincronizzazione ad un file di log:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-css&quot; data-lang=&quot;css&quot;&gt;&lt;span class=&quot;nt&quot;&gt;alias&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;syncall&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;push&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;A-server&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;.txt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;push&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;B-server&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;.txt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;push&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;C-server&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;.txt&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;un’altra cosa interessante, possono essere dei log arricchiti:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-css&quot; data-lang=&quot;css&quot;&gt;&lt;span class=&quot;nt&quot;&gt;alias&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;glog&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;git log --stat --max-count=10&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&quot;qualche-appunto-pratico-sulla-sicurezza&quot;&gt;Qualche appunto pratico sulla sicurezza&lt;/h2&gt;
&lt;p&gt;Cambiate SEMPRE la porta di default di ssh. SEMPRE. È il servizio più attaccato su sistemi UNIX-like. Anche se siete su CentOS e dovrete metter mano alle policy di SELINUX, fatelo. E mettete una porta alta, non standard. Non disattivate SELINUX o il firewall, per carità; sono cose che si configurano una tantum e poi funzionano sempre, mentre un’intrusione potrebbe rovinarvi, per sempre.&lt;/p&gt;

&lt;p&gt;Cambiate spesso le chiavi ssh se lavorate sulla rete internet. Ovviamente, non usate la stessa chiave per uploadare la nuova: fatevi un account a parte solo per queste operazioni, che usere solamente per cambio chiavi e compiti amministrativi: per i push in generale passa molta più roba, ed è attaccabile senza esagerate difficoltà se vi sniffano con una certa costanza. Magari un giorno scriverò anche di questo.&lt;/p&gt;

&lt;p&gt;Data la delicatezza dello scambio chiavi, sarebbe opportuno eseguire la prima sincronizzazione stando fisicamente collegati (o almeno in LAN) con il server, se il repo contiene dati sensibili.
Tenere tutto su ambienti virtualizzati con vm generalmente scollegate/spente che si attivano alla bisogna è sempre consigliabile.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;http://francescoprovino.com/git-faidate/&quot;&gt;Sopravvivere al velociraptor che cancella la tua tesi di laurea lanciando banane&lt;/a&gt; è stato originariamente pubblicato da Francesco Provino il &lt;a href=&quot;http://francescoprovino.com&quot;&gt;Francesco Provino&lt;/a&gt; su September 15, 2014.&lt;/p&gt;

  </content>
</entry>

</feed>
